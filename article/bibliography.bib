
@techreport{BitcoinWhitePaper,
  author      = {Satoshi Nakamoto},
  institution = {bitcoin.org},
  title       = {Bitcoin: A Peer-to-Peer Electronic Cash System},
  year        = {2008}
}

@online{BitcoinWiki,
  title   = {Bitcoin Wiki},
  url     = {https://en.bitcoin.it/wiki/},
  urldate = {November 16}
}

@article{Li2020,
  author  = {Tian Li and Anit Kumar Sahu and Ameet Talwalkar and Virginia Smith},
  title   = {Federated Learning: Challenges, Methods, and Future Directions},
  journal = {IEEE Signal Processing Magazine},
  year    = {2020},
  volume  = {37},
  number  = {3},
  pages   = {50--60},
  doi     = {10.1109/MSP.2020.2975749}
}

@misc{McMahan2016,
  title         = {Communication-Efficient Learning of Deep Networks from Decentralized Data},
  author        = {H. Brendan McMahan and Eider Moore and Daniel Ramage and Seth Hampson and Blaise Agüera y Arcas},
  year          = {2016},
  eprint        = {1602.05629},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
  url           = {https://arxiv.org/abs/1602.05629v1},
  version       = {1}
}


@inproceedings{UnsupervisedFL,
  author    = {Servetnyk, Mykola and Fung, Carrson C. and Han, Zhu},
  booktitle = {GLOBECOM 2020 - 2020 IEEE Global Communications Conference},
  title     = {Unsupervised Federated Learning for Unbalanced Data},
  year      = {2020},
  volume    = {},
  number    = {},
  pages     = {1-6},
  keywords  = {Self-organizing feature maps;Training;Privacy;Simulation;Collaborative work;Task analysis;Unsupervised learning;Federated learning;unsupervised learning;dual averaging algorithm;gradient weighting;distributed optimization;self-organizing maps},
  doi       = {10.1109/GLOBECOM42002.2020.9348203}
}


@article{ReinforcementFL,
  title     = {Federated reinforcement learning: techniques, applications, and open challenges},
  url       = {http://dx.doi.org/10.20517/ir.2021.02},
  doi       = {10.20517/ir.2021.02},
  journal   = {Intelligence \& Robotics},
  publisher = {OAE Publishing Inc.},
  author    = {Qi, Jiaju and Zhou, Qihao and Lei, Lei and Zheng, Kan},
  year      = {2021}
}

@online{oxford_federate,
  author = {Oxford University Press},
  title  = {Federate},
  year   = {2024},
  url    = {https://www.oxfordlearnersdictionaries.com/definition/english/federate},
  note   = {Accessed: 2024-11-17}
}

@book{MLBook,
  author    = {Kevin P. Murphy},
  publisher = {The MIT Press},
  isbn      = {0262018020},
  edition   = {1st},
  title     = {Machine Learning: A Probabilistic Perspective},
  year      = {2012}
}

@online{apple_fl,
  author = {Apple Inc.},
  year   = {2019},
  note   = {Accessed: 2024-11-18},
  url    = {https://web.archive.org/web/20221207175040/https://nips.cc/Expo/Conferences/2019/Schedule?talk_id=40}
}

@online{google_fl,
  author = {Google Inc.},
  url    = {https://federated.withgoogle.com/},
  note   = {Accessed: 2024-11-18}
}


@misc{problems-fl,
  title         = {Advances and Open Problems in Federated Learning},
  author        = {Peter Kairouz and H. Brendan McMahan and Brendan Avente et. Al.},
  year          = {2021},
  eprint        = {1912.04977},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
  url           = {https://arxiv.org/abs/1912.04977}
}

@inproceedings{AnalysisBFL,
  author    = {Meng, Lingxin and Guo, Yiting and Song, Shanshan and Cui, Chi},
  booktitle = {2023 IEEE International Conference on Electrical, Automation and Computer Engineering (ICEACE)},
  title     = {A Research and Analysis of Blockchain Federated Learning},
  year      = {2023},
  volume    = {},
  number    = {},
  pages     = {94-98},
  keywords  = {Privacy;Electric potential;Costs;Federated learning;Blockchains;Servers;Faces;Blockchain;Federated learning;Machine learning},
  doi       = {10.1109/ICEACE60673.2023.10442645}
}


@inproceedings{SurveryBFL,
  author    = {Agrawal, Neha and Mishra, Durgesh and Agrawal, Sukrati},
  booktitle = {2023 IEEE International Conference on ICT in Business Industry \& Government (ICTBIG)},
  title     = {A Comprehensive Survey on Blockchained Federated Learning System and Challenges},
  year      = {2023},
  volume    = {},
  number    = {},
  pages     = {1-4},
  keywords  = {Training;Surveys;Performance evaluation;Privacy;Federated learning;Scalability;Government;Blockchain;federated learning;machine learning},
  doi       = {10.1109/ICTBIG59752.2023.10456007}
}

@online{FLARE,
  author = {NVIDIA},
  title  = {Nvidia FLARE},
  url    = {https://github.com/NVIDIA/NVFlare},
  note   = {Accessed: 2024-11-18}
}

@misc{TESLA,
      title={Energy Demand Prediction with Federated Learning for Electric Vehicle Networks}, 
      author={Yuris Mulya Saputra and Dinh Thai Hoang and Diep N. Nguyen and Eryk Dutkiewicz and Markus Dominik Mueck and Srikathyayani Srikanteswara},
      year={2019},
      eprint={1909.00907},
      archivePrefix={arXiv},
      primaryClass={eess.SP},
      url={https://arxiv.org/abs/1909.00907}, 
}

@ARTICLE{Prof,
  author={Mazzocca, Carlo and Romandini, Nicolò and Mendula, Matteo and Montanari, Rebecca and Bellavista, Paolo},
  journal={IEEE Internet of Things Journal}, 
  title={TruFLaaS: Trustworthy Federated Learning as a Service}, 
  year={2023},
  volume={10},
  number={24},
  pages={21266-21281},
  keywords={Data models;Training;Blockchains;Smart contracts;Federated learning;Smart manufacturing;Industrial Internet of Things;Blockchain;federated learning (FL);federated learning as a service (FLaaS);security;trust;trustworthiness},
  doi={10.1109/JIOT.2023.3282899}}

@misc{backdoorFL,
      title={How To Backdoor Federated Learning}, 
      author={Eugene Bagdasaryan and Andreas Veit and Yiqing Hua and Deborah Estrin and Vitaly Shmatikov},
      year={2019},
      eprint={1807.00459},
      archivePrefix={arXiv},
      primaryClass={cs.CR},
      url={https://arxiv.org/abs/1807.00459}, 
}

@inproceedings{ATOMO,
author = {Wang, Hongyi and Sievert, Scott and Charles, Zachary and Liu, Shengchao and Wright, Stephen and Papailiopoulos, Dimitris},
title = {ATOMO: communication-efficient learning via atomic sparsification},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Distributed model training suffers from communication overheads due to frequent gradient updates transmitted between compute nodes. To mitigate these overheads, several studies propose the use of sparsified stochastic gradients. We argue that these are facets of a general sparsification method that can operate on any possible atomic decomposition. Notable examples include element-wise, singular value, and Fourier decompositions. We present ATOMO, a general framework for atomic sparsification of stochastic gradients. Given a gradient, an atomic decomposition, and a sparsity budget, ATOMO gives a random unbiased sparsification of the atoms minimizing variance. We show that recent methods such as QSGD and TernGrad are special cases of ATOMO and that sparsifiying the singular value decomposition of neural networks gradients, rather than their coordinates, can lead to significantly faster distributed training.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {9872–9883},
numpages = {12},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}


@online{GDPR,
  author = {European Parliament and Council of the European Union},
  title  = {General Data Protection Regulation (GDPR)},
  year   = {2016},
  url    = {https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX:32016R0679},
  note   = {Accessed: 2024-11-18}
}
@online{CCPA,
  author = {California Legislative Information},
  title  = {California Consumer Privacy Act (CCPA)},
  year   = {2018},
  url    = {https://leginfo.legislature.ca.gov/faces/billTextClient.xhtml?bill_id=201720180AB375},
  note   = {Accessed: 2024-11-18}
}

@misc{MultyPartyAggregation,
      title={Practical Secure Aggregation for Federated Learning on User-Held Data}, 
      author={Keith Bonawitz and Vladimir Ivanov and Ben Kreuter and Antonio Marcedone and H. Brendan McMahan and Sarvar Patel and Daniel Ramage and Aaron Segal and Karn Seth},
      year={2016},
      eprint={1611.04482},
      archivePrefix={arXiv},
      primaryClass={cs.CR},
      url={https://arxiv.org/abs/1611.04482}, 
}

@ARTICLE{FlwrBC,
  author={Cam, Nguyen Tan and Kiet, Vu Tuan},
  journal={IEEE Access}, 
  title={FlwrBC: Incentive Mechanism Design for Federated Learning by Using Blockchain}, 
  year={2023},
  volume={11},
  number={},
  pages={107855-107866},
  keywords={Federated learning;Servers;Blockchains;Data models;Computational modeling;Peer-to-peer computing;Biological system modeling;Artificial intelligence;blockchain;federated learning;machine learning;incentive mechanism},
  doi={10.1109/ACCESS.2023.3320045}}


@article{CoinAI,
   title={Coin.AI: A Proof-of-Useful-Work Scheme for Blockchain-Based Distributed Deep Learning},
   volume={21},
   ISSN={1099-4300},
   url={http://dx.doi.org/10.3390/e21080723},
   DOI={10.3390/e21080723},
   number={8},
   journal={Entropy},
   publisher={MDPI AG},
   author={Baldominos, Alejandro and Saez, Yago},
   year={2019},
   month=jul, pages={723} }

@ARTICLE{BlockFL,
  author={Kim, Hyesung and Park, Jihong and Bennis, Mehdi and Kim, Seong-Lyun},
  journal={IEEE Communications Letters}, 
  title={Blockchained On-Device Federated Learning}, 
  year={2020},
  volume={24},
  number={6},
  pages={1279-1283},
  keywords={Computational modeling;Blockchain;Training;Servers;Nickel;Delays;Data models;On-device machine learning;federated learning;blockchain;latency},
  doi={10.1109/LCOMM.2019.2921755}}

@misc{VBFL,
      title={Robust Blockchained Federated Learning with Model Validation and Proof-of-Stake Inspired Consensus}, 
      author={Hang Chen and Syed Ali Asif and Jihong Park and Chien-Chung Shen and Mehdi Bennis},
      year={2021},
      eprint={2101.03300},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2101.03300}, 
}

@misc{Tendermint,
      title={The latest gossip on BFT consensus}, 
      author={Ethan Buchman and Jae Kwon and Zarko Milosevic},
      year={2019},
      eprint={1807.04938},
      archivePrefix={arXiv},
      primaryClass={cs.DC},
      url={https://arxiv.org/abs/1807.04938}, 
}

@online{Ethereum,
  author = {Ethereum Foundation},
  title  = {Ethereum},
  year   = {2015},
  url    = {https://github.com/ethereum/wiki/wiki/white-paper},
  note   = {Accessed: 2024-11-20}
}